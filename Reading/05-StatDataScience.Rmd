# Statistics & Data Science

## An Introduction to Statistical Learning

So we realize actually–as often is the case, you can get some of the signal pretty quickly. But getting down to a very good error rate, in this case, trying to classify some of the harder to classify things is difficult.
7.2 Foundations of statistical natural language processing (by Christopher D. Manning & Hinrich schutze)

Zipf’s law: Human behavior and the principle of least effort. Principle of least effort: people will act so as to minimize their probable average rate of work (i.e. not only to minimize the work that they would have to do immediately, but taking due consideration of future work that might result from doing work poorly in the short term.)

Chomsky’s dictum: “Probability theory is inappropriate for formalizing the notion of grammaticality.”

## ASA on p-value

It is science’s dirtiest secret: The ‘scientific method’ of testing hypotheses by statistical analysis stands on a flimsy foundation. (Siegfried, 2010)

The problem is not that people use p-value poorly; it is that the vast majority of data analysis is not performed by people properly trained to perform data analysis. (Leek, 2014)

The statistical community has been deeply concerned about issues of reproducibility and replicability of scientific conclusions.

Clarify some widely agreed principles:

P-values can indicate how incompatible the data are with a specified statistical model
The incompatibility can be interpreted as casting doubt on or providing evidence against the null hypothesis or the underlying assumptions.

P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone It is a statement about data in relation to a specified hypothetical explanation and is not a statement about the explanation itself.

Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold Need to consider other factors: (1) design of a study (2) quality of the measurement (3) external evidence for the phenomenon under study (4) validity of assumptions that underlie the data analysis.

Proper inference requires full reporting and transparency
Also need to disclose: number of hypotheses explored, all data collection decisions, all statistical analyses conducted, p-values computed
Avoid: cherry-picking (aka: data dredging, significance chasing and significance questing, selective inference, p-hacking)
A p-value or statistical significance does not measure the size of an effect or the importance of a result Smaller p-values do not necessarily imply the presence of larger or more important effects. Larger p-values do not imply a lack of importance or even lack of effect. Any effect, no matter tiny can produce a small p-value if the sample size or measurement precision is high enough and large effects may produce unimpressive p-values if the sample size is small or measurements are imprecise (does large p-value indicate uncertainty of making conclusion from the data using current model?)

By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.
Also try other available methods
Other approaches: confidence, credibility or prediction intervals (?), Bayesian methods, likelihood ratios (?) or Bayes Factors, decision-theoretic modeling (?) and false discovery rates (?).

## A company’s 5 levels of analytical maturity

The first theme is a company’s 5 levels of analytical maturity and its application to several companies.

Level 1: reporting data Level 2: building predictive models Level 3: streamline predictive process and make it repeatable Level 4: repeat the process at large to have whole organization catch on Level 5: define strategies that allow sustainability

Many companies get stuck from level 2 to 3 that they cannot turn the predictive models into a repeatable process for analytics. The difficulty lies within communication and collaboration between data scientist building models and data engineers deploy models. There’s a general chasm between modeling environment and deployment environment. It can be filled with the right people, right senior buy in and a LOT of meetings.

## Practical text analytics

Big data does not have a consistent and concise definition. We might say somewhat lightheartedly that it appears to involve more data than you can handle comfortably with whatever software and hardware you now own.

## Data science team

It is an article for data science in startups but we can still learn some general points.

- What can data science do?
    1. Improving the products： 
        - Rely on a virtuous cycle where products collect usage data that becomes the fodder for algorithms which in turn offer users a better experience.
        - The first version of your product has to address what data science calls the “cold start” problem
        — it has to provide a “good enough” experience to initiate the virtuous cycle of data collection and data-driven improvement. It needs product managers and engineers to implement solution. (需要至少开始有人使用产品，进入“数据收集-数据驱动改进产品”的循环)
Data scientists collaborate with engineers
Decide whether data scientists implement product enhancements themselves or partner with engineers who implement them. Either approach can work, but it’s important to formalize it and establish shared expectations across the organization. Otherwise, you’ll struggle to get improvements into production, and you’ll lose talented data scientists who feel unproductive and undervalued.
Skills: machine learning knowledge and production-level engineering skills
Improving the decisions：
Decision science uses data analysis and visualization to inform business and product decisions. The decision-maker may be anywhere in the organization — from a product manager determining how to set priorities on a road map to the executive team making bet-the-company strategic decisions.
Characteristics of decision science:
Subjective, requiring data scientists to deal with unknown variables and missing context
Complex, with many moving parts that lack clear causal relationships
Decision science problems are measurable and impactful — the result of making the decision is concrete and significant for the business[Hui: 文章的作者还提到一点说是公司之前不需要解决的新问题。个人不同意这一点。作者这么说可能因为这篇文章是针对创业企业。对于大型传统企业，遇到的大部分都是很老的决策问题，只是之前只是靠猜而已……额，说好听些就是行业专家的猜测。]
Sound like data analytics but decision science should do more than produce reports and dashboards. Data scientists shouldn’t be doing work that can be delivered using off-the-shelf business intelligence tools.
Not always need decision science (In the two cases, businesses need to rely on intuition and experimentation):
Some decisions are too small to justify the investment
Lack the data to meaningfully analyze them
Good decision scientists know their own limitations
Skills: business and product sense, systematic thinking, and strong communication skills
Should you be investing in data science?
Invest: it’ll be critical to your success
Not invest: it’ll just be an expensive distraction
Are you committed to using data science to either inform strategic decisions or build data products?
If you’re not committed to using data science toward one of these goals, then don’t hire data scientists.
Culture of data-driven decision making is necessary
You may not need them on day one, but it takes time for you to hire the right people — and time for them to get to know your data and your business. You’ll need all that to happen before they can apply data science to drive decision making.
Data products can create value and delight users through improved optimization, relevance, etc. If these are on your product roadmap, you should bring data scientists in early to make the design decisions that will set you up for long-term success. Data scientists can make key decisions about product design, data collection, and systems architecture that are critical foundations for building magical-seeming products.
Will you be able to collect the data you need and act on it?
Data science requires data: quantity and quality
Data science only matters if data drives action. Data should inform product changes and drive the organization’s key performance indicators (KPIs). Instrumentation requires a commitment across the organization to identify what data each product needs to collect and establish the infrastructure and processes for collecting and maintaining that data. To be successful, instrumentation requires collaboration among data scientists, engineers, and product managers — which in turn requires executive commitment. Data-driven decision making requires a top-down commitment. From the CEO down, the organization has to commit to making decisions using data, rather than based on the highest paid person’s opinion.
Do you need data science to be a core competency, or can you outsource it?
If data science is solving problems that are critical to your success, then you can’t afford to outsource it. Also, off-the-shelf solutions tend to be rigid. If your business is taking a unique approach to a problem (e.g. collecting new kinds of data or using the results in novel ways), it’s unlikely that an off-the-shelf solution will be flexible enough to adapt to it.
Where does data science belong in your organization?
A standalone team -Your data science team acts as an autonomous unit parallel to engineering. The head of data science is a key leader and typically reports to the head of product or engineering — or even directly to the CEO.
Pros:
Autonomy
Well positioned to tackle whatever problems it deems most valuable
Demonstrates that the company sees data as a first-class asset, which will help them attract world-class talent.
Works particularly well for decision science teams. Even though decision scientists collaborate closely with product teams, their independence helps them to make hard calls, like telling PMs that their product’s metrics aren’t good enough to justify a launch. Decision scientists also benefit a lot from cross-pollination, both to understand how different product metrics depend on one another and to share more general learnings about experimentation and data analysis.
Cons:
Risk of marginalization. As companies grow and organize into product teams, they often prefer to be self-sufficient. Even when they could benefit from collaboration with data scientists, product teams simply don’t want to depend on resources they don’t control. Instead, they rely on themselves — even hiring their own data scientists under other names like “research engineers” — to get things done. If product teams refuse to work with the standalone data science team, then that team becomes marginalized and ineffective. Again, that’s when you start losing good talent.
An embedded model
Data science team brings in talented people and farms them out to the rest of the company. There’s still a head of data science, but he or she is mostly a hiring manager and coach.
The embedded model is the polar opposite of the standalone model: It gives up autonomy to ensure utility.
Pros: data scientists join the product teams that most need their services, and get to work on a wide variety of problems throughout the organization.
Cons:
not all data scientists are happy giving up autonomy (in fact, many are not good at it at all). Data scientist job descriptions emphasize creativity and initiative, and embedded roles often require them to defer to the leadership of the teams in which they are embedded.
Data scientists will feel like second-class citizens as embedded team members — their product leads don’t feel responsible for their growth and happiness, while their managers won’t feel directly vested in their work.
We’ve seen some companies embed data science managers, but this approach only works once you have a fairly large data science team.
Integrated team
No separate data science team. Instead, product teams hire and manage their own data scientists.
Pros: This optimizes for organizational alignment. By making data scientists first-class members of their product teams, it addresses the downsides of the standalone and embedded models. To the extent that data scientists, software engineers, designers, and product managers work on shared product goals, the integrated model instills collective team ownership of those goals. This is how you avoid the breakdowns that can occur when narrowly focused functional teams diverge in their goals and end up mired in dependencies that are too often ignored or delayed.
Cons:
It dilutes the identity of data science. Individual data scientists identify with their associated product teams, rather than a centralized data science team.
You also sacrifice the flexibility of the embedded model, since it’s harder to move people around based on their skills and interests.
he integrated model can create challenges for scientists’ career growth, since the manager of an integrated team may not be in the best position to value or reward their accomplishments.
Over time, the impact that a data science team has will be far higher if you build a diverse team with extremely different backgrounds, skill-sets, and world views.

This will ensure they think as holistically as possible about their domain, and will encourage creativity and innovation over time.

## Hadoop v.s. Spark

Hadoop and Spark are both Big Data frameworks – they provide some of the most popular tools used to carry out common Big Data-related tasks. 

Hadoop, for many years, was the leading open source Big Data framework but recently the newer and more advanced Spark has become the more popular of the two Apache Software Foundation tools. 

However they do not perform exactly the same tasks, and they are not mutually exclusive, as they are able to work together. Although Spark is reported to work up to 100 times faster than Hadoop in certain circumstances, it does not provide its own distributed storage system. 

Distributed storage is fundamental to many of today’s Big Data projects as it allows vast multi-petabyte datasets to be stored across an almost infinite number of everyday computer hard drives, rather than involving hugely costly custom machinery which would hold it all on one device. These systems are scalable, meaning that more drives can be added to the network as the dataset grows in size. 

As I mentioned, Spark does not include its own system for organizing files in a distributed way (the file system) so it requires one provided by a third-party. For this reason, many Big Data projects involve installing Spark on top of Hadoop, where Spark’s advanced analytics applications can make use of data stored using the Hadoop Distributed File System (HDFS). 

What really gives Spark the edge over Hadoop is speed. Spark handles most of its operations “in memory” – copying them from the distributed physical storage into far faster logical RAM. This reduces the amount of time-consuming writing and reading to and from slow, clunky mechanical hard drives that need to be done under Hadoop’s MapReduce system. 

MapReduce writes all of the data back to the physical storage medium after each operation. This was originally done to ensure a full recovery could be made in case something goes wrong – as data held electronically in RAM is more volatile than that stored magnetically on disks. However, Spark arranges data in what is known as Resilient Distributed Datasets, which can be recovered following failure. 

Spark’s functionality for handling advanced data processing tasks such as real-time stream processing and machine learning is way ahead of what is possible with Hadoop alone. This, along with the gain in speed provided by in-memory operations, is the real reason, in my opinion, for its growth in popularity. Real-time processing means that data can be fed into an analytical application the moment it is captured, and insights immediately fed back to the user through a dashboard, to allow the action to be taken. This sort of processing is increasingly being used in all sorts of Big Data applications, for example, recommendation engines used by retailers, or monitoring the performance of industrial machinery in the manufacturing industry.

Spark includes its machine learning libraries, called MLib, whereas Hadoop systems must be interfaced with a third-party machine learning library, for example, Apache Mahout. 

Many of the big vendors (i.e. Cloudera) now offer Spark as well as Hadoop, so will be in a good position to advise companies on which they will find most suitable, on a job-by-job basis. For example, if your Big Data consists merely of a huge amount of very structured data (i.e customer names and addresses) you may not need the advanced streaming analytics and machine learning functionality provided by Spark. This means you would be wasting time, and probably money, having it installed as a separate layer over your Hadoop storage. Spark, although developing very quickly, is still in its infancy, and the security and support infrastructure is not as advanced. 

## Data Quality

Kaushak, Data Quality Sucks, Let’s Just Get Over It, (2006)
Assume those managing the data have a level of comfort with the data;
Start making decisions that you are comfortable with;
over time drill deeper in micro specific areas and learn more;
Get more comfortable with data and its limitations over time;
Consistency in calculations=Good.
8.5 Data Visualization

Three rules to visualize insights with impact:

Highlight your message and eliminate distractions;
Use visual cues to help lead your audience through your insight;
Use contrast (size, color) to capture the reader’s attention.
8.6 Big Data (大数据的冲击)

8.6.1 What is big data

Trend: Analyzing non-structured data

Genernalized definition:
structured data
non-structured data(text,voice,vedio,GPS,sensor)
Data storage/processing/analyzing techniques: Hadoop, NoSQL, machine learning/satatistics
Data Scientist/Data oriented organization
Decide.com/FlightCaster

Bottle neck of machine learning: store and process big data (doubt it)

From point information to thread information
Point information: purchase a product, received a service……
We need thread information to answer WHY!
Thread information: customer interaction data (non-structured or historical behavior)
8.6.2 Walk Between Privacy and Innovation

Collaborative Filtering (Amazon): method of making automative predictions about the interests of a user by collecting preferences or taste information from many users (collaborating). The underline assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B’s opinion on a different issue X than to have the opinion on X of a person chosen randomly.

Rapleaf: using email address/name to get personal profile (linked to information on Facebook)

8.6.3 Data Aggregator

Pay as You Drive: car insurance (provide discount according to the driving habit)
For company with internal technique skill: collection, cleaning, analyzing, result delivery, implementation
Data Aggregator: provide some hard to collect off-line data (what are those?)
Who will be data aggregator: those who develop devices for data entry and collection
More personal, more useful, harder to get
Payment service companies (VISA, American Express etc.): on the road to data aggregator [VISA collabrate with GAP]
Aggregate data
Internal Data + External Data–>Premiun Data (multiplication effect)
Example: Catalina Marketing and Nilson evaluate the TV ad by studying the association between audience rating and actual purchse
What data to get?
Example: iphone App: Nike+GPS, get running route (anonymous) and use the information to get insight for store location
8.6.4 Data Scientist

Sexy
Characters:
Communication skill
Entrepreneuership: explore how to make data useful, lead to new data based services
Curiosity: not limited in art, techniques, medicine, natural science……but keenly curious about different areas. By analyzing data from differnt fields, data scientist with curiosity will find bonanza
8.6.5 What machine can not do?

We have no chance of competing against machines on frequent, high-volume tasks.
Machine cannot compete with us when it comes to tackling novel situations, and this puts a fundamental limit on the human tasks that machines will automate. It needs to learn from large volumes of past data. Humans have the ability to connect seemingly disparate threads to solve problems we’ve never seen before.
So what does this mean for the future of work? The future state of any single job lies in the answer to a single question: To what extent is that job reducible to frequent, high-volume tasks, and to what extent does it involve tackling novel situations? On frequent, high-volume tasks, machines are getting smarter and smarter.
The copy behind a marketing campaign needs to grab consumers’ attention. It has to stand out from the crowd. Business strategy means finding gaps in the market, things that nobody else is doing. It will be humans that are creating the copy behind our marketing campaigns, and it will be humans that are developing our business strategy.
8.7 Data science position

Prediction for 2017:

Continuous learning will be front and center. Learning is a way of life.
Require time commitment from both individual and the company.
Always absorbing what is going on there.
They are naturally curious people.
Companies will “train up” existing talent
Predictions 1&2 lead to longer tenure
Current situation is the opposite
Stagnating, lack of job satisfaction
HR analytics will be standard at larger firms
Add headhunter support for analytics hiring
Education options will thin out (a bit)
Previous: MOOC/Bootcamp
Separation between : money deal $15000/12 weeks v.s. high quality education
Analytics ROI will be scrutinized
What is the associate payback?
How long does it take to see results? How much has been invested?
It is important to tie analytics to real business problem
Analytics findings will be scrutinized
Confidence for the magic of analytics will shadowed
The internet of things draws more interest
Mission-driven careers are on the rise
Advise: Be open to change

8.8 Everybody Lies

“Makingsense” says that there are things data can not tell us. “Everybody Lies” says there are things we cannot see other than using data and the key is where to find the right data.

condom estimates
Female: 55/year, 16% using condom, 1.1 billion condoms/year
Male: 1.6 billion condoms/year
Reality: 600 million condoms/year
sexless marriage > unhappy marriage > loveless marriage
racial discrimination, People in the esat coast (心机深)
significant effect (small data); small effect (big data)
pancreatic cancer symptoms by searching history
Weather v.s depression (Hawaii v.s Chicago, search for “depression” 40%)
Gender discrination:
Boys: intelligent, happy
Girls: over-weight, pretty
8.9 Database design

Plan Ahead
understand the data and what it’s supposed to do
database modeling and software development are different
Document Your Model
Use a name convention
Document the design
New administrator can understand without having to come back to you for explanation
Think Carefully About Keys: primary keys, foreign keys, artificial keys
Use Integrity Checks Carefully
Define integrity rules
Currency for different countries, define messages as incoming or outgoing
Don’t Forget Indexes in Your Design
Use separate tables for domain objects rather than cramming them into a single table
Define an Archiving Strategy
Test Early, Test Often
With analytics data, scale matters: good estimate of usage
one server is never enough
Rollups make things cheaper but at a great expense later: tracking every action in a raw way allows for the development of insights that tell even more important stories.
User log
Reliability: set up alerting and monitoring systems and make it someone else’s problem through hosted offerings.
8.10 Data Driven Marketer

Challenges:
Cross-device
Classic culture issues:
Overcome the fear of failure
Get comfortable with ambiguity
Break down silos
Trust data over whims, gut reactions, and even past experiences
Data to include: television data, competitive data, social data
Train to transform:
give everyone the training they need
driving marketing strategy, validating benchmarks, evaluating and providing actionable data insights
clear on your data strategy (documentation)
Three pillars of your integrated strategy:
the right data: manage the data pipeline, put data in the context (how data was collected), act fast and don’t wait until data is perfect,
the right culture:
formalize points of alignment and collaboration across different functions, such as brand marketing, digital media and analytics departments
marketing IT
your company, not the agency owns the data
better training
the right technology